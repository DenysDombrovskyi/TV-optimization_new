import streamlit as st
import pandas as pd
import numpy as np
import io
import matplotlib.pyplot as plt
import plotly.express as px

# -----------------------------
#            Utils
# -----------------------------

TOP_CHANNEL_GROUPS = {
    "–û—É—à–µ–Ω": ["–°–¢–ë", "–ù–æ–≤–∏–π –∫–∞–Ω–∞–ª", "ICTV2"],
    "Sirius": ["1+1 –£–∫—Ä–∞—ó–Ω–∞", "–¢–ï–¢", "2+2"],  # ‚úÖ –¢–ï–¢ —É Sirius
    "Space": ["–ù–¢–ù"],
}
ALL_TOP_CHANNELS = [ch for lst in TOP_CHANNEL_GROUPS.values() for ch in lst]

st.set_page_config(page_title="–û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è –¢–í —Å–ø–ª—ñ—Ç–∞", layout="wide")
st.title("üì∫ –ï–≤—Ä–∏—Å—Ç–∏—á–Ω–∞ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è –¢–í —Å–ø–ª—ñ—Ç–∞ | Dentsu X")

# -----------------------------
#       Validation helpers
# -----------------------------

def validate_structure(df: pd.DataFrame) -> bool:
    """–ë–∞–∑–æ–≤–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–æ–ª–æ–Ω–æ–∫."""
    base_required = ["–ö–∞–Ω–∞–ª", "–°–•"]
    for col in base_required:
        if col not in df.columns:
            st.error(f"‚ùå –í –∞—Ä–∫—É—à—ñ '–°–ø-–≤–æ' –≤—ñ–¥—Å—É—Ç–Ω—ñ–π –æ–±–æ–≤'—è–∑–∫–æ–≤–∏–π —Å—Ç–æ–≤–ø—á–∏–∫ '{col}'.")
            return False
    return True

def get_available_ba(df: pd.DataFrame) -> list:
    """–ó–Ω–∞—Ö–æ–¥–∏–º–æ –≤—Å—ñ –¥–æ—Å—Ç—É–ø–Ω—ñ BA –∑–∞ –ø—Ä–µ—Ñ—ñ–∫—Å–∞–º–∏ –∫–æ–ª–æ–Ω–æ–∫."""
    price_bas = [c.replace("–¶—ñ–Ω–∞_", "") for c in df.columns if c.startswith("–¶—ñ–Ω–∞_")]
    trp_bas   = [c.replace("TRP_", "") for c in df.columns if c.startswith("TRP_")]
    aff_bas   = [c.replace("Affinity_", "") for c in df.columns if c.startswith("Affinity_")]
    # –ª–∏—à–∞—î–º–æ –ª–∏—à–µ —Ç—ñ BA, —è–∫—ñ –º–∞—é—Ç—å –≤–µ—Å—å –Ω–∞–±—ñ—Ä –∫–æ–ª–æ–Ω–æ–∫
    all_ba = sorted(set(price_bas) & set(trp_bas) & set(aff_bas))
    return all_ba

def validate_ba_columns_exist(df: pd.DataFrame, buying_audiences: dict) -> bool:
    """–ü–µ—Ä–µ–∫–æ–Ω—É—î–º–æ—Å—å, —â–æ –¥–ª—è –≤—Å—ñ—Ö –≤–∏–±—Ä–∞–Ω–∏—Ö –°–• —ñ—Å–Ω—É—é—Ç—å –∫–æ–ª–æ–Ω–∫–∏ –¶—ñ–Ω–∞/TRP/Affinity."""
    ok = True
    for sh, ba in buying_audiences.items():
        missing = [col for col in (f"–¶—ñ–Ω–∞_{ba}", f"TRP_{ba}", f"Affinity_{ba}") if col not in df.columns]
        if missing:
            st.error(f"‚ùå –î–ª—è –°–• '{sh}' –≤—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –ë–ê '{ba}': {', '.join(missing)}")
            ok = False
    return ok

def coerce_numeric_cols(df: pd.DataFrame, cols: list) -> pd.DataFrame:
    """–ü–µ—Ä–µ—Ç–≤–æ—Ä—é—î–º–æ –≤ —á–∏—Å–ª–æ–≤—ñ –∑ NaN -> 0 (–¥–ª—è —Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ)."""
    for c in cols:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    return df

# -----------------------------
#        Core logic
# -----------------------------

def heuristic_split_within_group(group_df: pd.DataFrame, total_group_budget: float) -> pd.DataFrame:
    """
    –ï–≤—Ä–∏—Å—Ç–∏—á–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª –±—é–¥–∂–µ—Ç—É –≤—Å–µ—Ä–µ–¥–∏–Ω—ñ –ø—ñ–¥–≥—Ä—É–ø–∏ –∫–∞–Ω–∞–ª—ñ–≤:
    –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç ‚Äî –º—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ '—Ü—ñ–ª—å–æ–≤–∞ –≤–∞—Ä—Ç—ñ—Å—Ç—å TRP' (–¶—ñ–Ω–∞/TRP * Affinity).
    –ë—é–¥–∂–µ—Ç –Ω–∞ –∫–∞–Ω–∞–ª –æ–±–º–µ–∂–µ–Ω–æ –π–æ–≥–æ '–ø–æ—Ç–µ–Ω—Ü—ñ–∞–ª–æ–º' = –¶—ñ–Ω–∞ * TRP.
    """
    group_df = group_df.copy()

    if group_df.empty or total_group_budget <= 0:
        group_df["–û–ø—Ç–∏–º–∞–ª—å–Ω–∏–π –±—é–¥–∂–µ—Ç"] = 0.0
        group_df["–û–ø—Ç–∏–º–∞–ª—å–Ω–∞ —á–∞—Å—Ç–∫–∞ (%)"] = 0.0
        return group_df

    # –í–∞—Ä—Ç—ñ—Å—Ç—å –ø–æ–∫—É–ø–Ω–æ–≥–æ TRP –∑ –æ–±—Ä–æ–±–∫–æ—é –¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ –Ω—É–ª—å
    cost_per_buying_trp = np.divide(
        group_df["–¶—ñ–Ω–∞"], group_df["TRP"],
        out=np.full_like(group_df["TRP"].to_numpy(dtype=float), np.inf, dtype=float),
        where=group_df["TRP"].to_numpy(dtype=float) != 0
    )
    # –í–∞—Ä—Ç—ñ—Å—Ç—å —Ü—ñ–ª—å–æ–≤–æ–≥–æ TRP
    cost_per_targeted_trp = cost_per_buying_trp * group_df["Affinity"].fillna(1.0)

    # –†–æ–∑–ø–æ–¥—ñ–ª—è—î–º–æ –±—é–¥–∂–µ—Ç —É –ø–æ—Ä—è–¥–∫—É –∑—Ä–æ—Å—Ç–∞–Ω–Ω—è cost_per_targeted_trp
    sorted_idx = cost_per_targeted_trp.sort_values(ascending=True).index
    shares = pd.Series(0.0, index=group_df.index)
    remaining = float(total_group_budget)

    for idx in sorted_idx:
        row = group_df.loc[idx]
        cost = cost_per_targeted_trp.loc[idx]
        if pd.notna(cost) and np.isfinite(cost):
            capacity = float(row["–¶—ñ–Ω–∞"]) * float(row["TRP"])  # –º–∞–∫—Å–∏–º—É–º, —è–∫–∏–π "–º—ñ—Å—Ç–∏—Ç—å" –∫–∞–Ω–∞–ª
            add = min(remaining, capacity)
            shares.loc[idx] = add
            remaining -= add
            if remaining <= 1e-9:
                break

    group_df["–û–ø—Ç–∏–º–∞–ª—å–Ω–∏–π –±—é–¥–∂–µ—Ç"] = shares
    # –ß–∞—Å—Ç–∫–∏ –≤—Å–µ—Ä–µ–¥–∏–Ω—ñ –°–• —Ä–∞—Ö—É–≤–∞—Ç–∏–º–µ–º–æ –ø—ñ–∑–Ω—ñ—à–µ, –∫–æ–ª–∏ –∑–Ω–∞—Ç–∏–º–µ–º–æ total_sx_budget
    return group_df

def run_multi_group_optimization(df: pd.DataFrame, buying_audiences: dict) -> pd.DataFrame:
    """
    –ì–æ–ª–æ–≤–Ω–∞ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è:
    1) –î–ª—è –∫–æ–∂–Ω–æ–≥–æ –°–• —Ñ—ñ–∫—Å—É—î–º–æ –±—é–¥–∂–µ—Ç–∏ –¥–ª—è –∫–æ–∂–Ω–æ—ó —Ç–æ–ø-–≥—Ä—É–ø–∏ (= –ø–æ—Ç–æ—á–Ω–∞ —Å—É–º–∞ –¶—ñ–Ω–∞*TRP —É —Ü—ñ–π –ø—ñ–¥–º–Ω–æ–∂–∏–Ω—ñ)
    2) –†–æ–∑–ø–æ–¥—ñ–ª—è—î–º–æ —ó—Ö —É—Å–µ—Ä–µ–¥–∏–Ω—ñ –≥—Ä—É–ø –∑–∞ –µ–≤—Ä–∏—Å—Ç–∏–∫–æ—é
    3) –†–µ—à—Ç—É –∫–∞–Ω–∞–ª—ñ–≤ –æ–ø—Ç–∏–º—ñ–∑—É—î–º–æ –æ–∫—Ä–µ–º–æ –Ω–∞ —ó—Ö–Ω—ñ–π —Å—É–º—ñ
    4) –û–±—á–∏—Å–ª—é—î–º–æ —á–∞—Å—Ç–∫–∏ –≤—ñ–¥ total_sx_budget —ñ –Ω–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ –¥–æ 100% (–∑–±–µ—Ä—ñ–≥–∞—é—á–∏ –ø—Ä–æ–ø–æ—Ä—Ü—ñ—ó)
    """
    df = df.copy()

    # –ü—ñ–¥—Ç—è–≥–Ω—É—Ç–∏ –≤–∏–±—Ä–∞–Ω—É –ë–ê –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ä—è–¥–∫–∞
    df["–¶—ñ–Ω–∞"] = df.apply(lambda r: r.get(f"–¶—ñ–Ω–∞_{buying_audiences.get(r['–°–•'], '')}", 0), axis=1)
    df["TRP"] = df.apply(lambda r: r.get(f"TRP_{buying_audiences.get(r['–°–•'], '')}", 0), axis=1)
    df["Affinity"] = df.apply(lambda r: r.get(f"Affinity_{buying_audiences.get(r['–°–•'], '')}", 1.0), axis=1).fillna(1.0)

    coerce_numeric_cols(df, ["–¶—ñ–Ω–∞", "TRP", "Affinity"])

    all_results = []

    for sh, sh_df in df.groupby("–°–•", sort=False):
        sh_df = sh_df.copy()
        total_sx_budget = float((sh_df["–¶—ñ–Ω–∞"] * sh_df["TRP"]).sum())

        # –†–æ–∑–±–∏–≤–∞—î–º–æ –Ω–∞ —Ç–æ–ø-–ø—ñ–¥–º–Ω–æ–∂–∏–Ω–∏ —Ç–∞ "—Ä–µ—à—Ç—É"
        remaining_df = sh_df.copy()
        optimized_parts = []

        for group_name, channels in TOP_CHANNEL_GROUPS.items():
            part = remaining_df[remaining_df["–ö–∞–Ω–∞–ª"].isin(channels)].copy()
            if not part.empty:
                part_budget = float((part["–¶—ñ–Ω–∞"] * part["TRP"]).sum())  # —Ñ—ñ–∫—Å–æ–≤–∞–Ω–∏–π –±—é–¥–∂–µ—Ç –≥—Ä—É–ø–∏
                part_opt = heuristic_split_within_group(part, part_budget)
                optimized_parts.append(part_opt)
                # –í–∏–∫–∏–¥–∞—î–º–æ –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω—ñ –ø—ñ–¥–º–Ω–æ–∂–∏–Ω–∏ –∑ ‚Äú—Ä–µ—à—Ç–∏‚Äù
                remaining_df = remaining_df[~remaining_df["–ö–∞–Ω–∞–ª"].isin(channels)]

        if not remaining_df.empty:
            rest_budget = float((remaining_df["–¶—ñ–Ω–∞"] * remaining_df["TRP"]).sum())
            rest_opt = heuristic_split_within_group(remaining_df, rest_budget)
            optimized_parts.append(rest_opt)

        sh_result = pd.concat(optimized_parts, axis=0) if optimized_parts else sh_df.copy()
        # —á–∞—Å—Ç–∫–∏ –≤—ñ–¥ total_sx_budget
        if total_sx_budget > 0:
            sh_result["–û–ø—Ç–∏–º–∞–ª—å–Ω–∞ —á–∞—Å—Ç–∫–∞ (%)"] = sh_result["–û–ø—Ç–∏–º–∞–ª—å–Ω–∏–π –±—é–¥–∂–µ—Ç"] / total_sx_budget * 100.0
        else:
            sh_result["–û–ø—Ç–∏–º–∞–ª—å–Ω–∞ —á–∞—Å—Ç–∫–∞ (%)"] = 0.0

        all_results.append(sh_result)

    all_results = pd.concat(all_results, axis=0)

    # –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ –ø–æ –∫–æ–∂–Ω–æ–º—É –°–• –¥–æ 100% (–∑–±–µ—Ä—ñ–≥–∞—é—á–∏ –ø—Ä–æ–ø–æ—Ä—Ü—ñ—ó ‚Äî –æ—Ç–∂–µ, —Å—É–º–∞—Ä–Ω—ñ —á–∞—Å—Ç–∫–∏ —Ç–æ–ø—ñ–≤ –Ω–µ –∑–º—ñ–Ω—è—Ç—å—Å—è)
    def _norm(x: pd.Series) -> pd.Series:
        s = x.sum()
        return x if s == 0 else x / s * 100.0

    all_results["–û–ø—Ç–∏–º–∞–ª—å–Ω–∞ —á–∞—Å—Ç–∫–∞ (%)"] = all_results.groupby("–°–•")["–û–ø—Ç–∏–º–∞–ª—å–Ω–∞ —á–∞—Å—Ç–∫–∞ (%)"].transform(_norm)

    # –û–±—á–∏—Å–ª—é—î–º–æ —Å–ª—É–∂–±–æ–≤—É –º–µ—Ç—Ä–∏–∫—É: –≤–∞—Ä—Ç—ñ—Å—Ç—å —Ü—ñ–ª—å–æ–≤–æ–≥–æ TRP (–¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ–π/–≤–∏–¥—ñ–ª–µ–Ω—å)
    with np.errstate(divide="ignore", invalid="ignore"):
        all_results["–¶—ñ–Ω–∞_–¢–†–ü_—Ü—ñ–ª—å–æ–≤–∏–π"] = (
            np.divide(
                all_results["–¶—ñ–Ω–∞"], all_results["TRP"],
                out=np.full_like(all_results["TRP"].to_numpy(dtype=float), np.inf, dtype=float),
                where=all_results["TRP"].to_numpy(dtype=float) != 0
            ) * all_results["Affinity"].fillna(1.0)
        )

    return all_results

# -----------------------------
#         Demo data
# -----------------------------

def make_demo_df() -> pd.DataFrame:
    """–°—Ç–≤–æ—Ä—é—î —Ç–µ—Å—Ç–æ–≤–∏–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º, —â–æ —ñ–º—ñ—Ç—É—î –∞—Ä–∫—É—à '–°–ø-–≤–æ'."""
    data = {
        "–ö–∞–Ω–∞–ª": [
            "–°–¢–ë", "–ù–æ–≤–∏–π –∫–∞–Ω–∞–ª", "ICTV2", "1+1 –£–∫—Ä–∞—ó–Ω–∞", "–¢–ï–¢", "2+2", "–ù–¢–ù",
            "ICTV", "–£–∫—Ä–∞—ó–Ω–∞ 24", "–ü–ª—é—Å–ü–ª—é—Å"
        ],
        "–°–•": [
            "FMCG", "FMCG", "FMCG", "FMCG", "FMCG", "FMCG", "FMCG",
            "Finance", "Finance", "Finance"
        ],
        # BA = A18-54
        "–¶—ñ–Ω–∞_A18-54": [100, 110, 95, 130, 90, 85, 70, 120, 140, 60],
        "TRP_A18-54":  [15,  12,  11,  14, 13, 9,   8,  10,  8,   7 ],
        "Affinity_A18-54": [1.0, 1.05, 0.95, 1.1, 0.9, 1.0, 0.85, 1.0, 1.1, 0.9],
        # BA = W25-45
        "–¶—ñ–Ω–∞_W25-45": [90, 100, 92, 120, 88, 80, 75, 115, 135, 65],
        "TRP_W25-45":  [14, 11,  12, 13,  12, 8,  9,  9,   8,   7],
        "Affinity_W25-45": [1.1, 1.0, 1.0, 1.05, 0.95, 0.9, 0.9, 1.0, 1.1, 0.95],
    }
    df = pd.DataFrame(data)
    return df

# -----------------------------
#         UI: Input
# -----------------------------

st.sidebar.header("–î–∞–Ω—ñ")
use_demo = st.sidebar.toggle("üß™ –í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ –¥–µ–º–æ-–¥–∞–Ω—ñ (–±–µ–∑ Excel)", value=False)

df_input = None
if use_demo:
    df_input = make_demo_df()
    st.success("‚úÖ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è –¥–µ–º–æ-–¥–∞–Ω—ñ.")
else:
    uploaded = st.file_uploader("–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ Excel-—Ñ–∞–π–ª –∑ –∞—Ä–∫—É—à–µ–º '–°–ø-–≤–æ'", type=["xlsx"])
    if uploaded is not None:
        try:
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≤–∏—Ö—ñ–¥–Ω–∏–π –ø–æ—Ä—è–¥–æ–∫ —Ä—è–¥–∫—ñ–≤
            df_input = pd.read_excel(uploaded, sheet_name="–°–ø-–≤–æ", skiprows=2, engine="openpyxl")
            st.success("‚úÖ –î–∞–Ω—ñ —É—Å–ø—ñ—à–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ!")
        except Exception as e:
            st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ —Ñ–∞–π–ª—É: {e}")

if df_input is None:
    st.info("‚¨ÜÔ∏è –ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ —Ñ–∞–π–ª –∞–±–æ —É–≤—ñ–º–∫–Ω—ñ—Ç—å –¥–µ–º–æ-–¥–∞–Ω—ñ –≤ –ª—ñ–≤—ñ–π –ø–∞–Ω–µ–ª—ñ.")
    st.stop()

# –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π –ø–æ—Ä—è–¥–æ–∫ –∫–∞–Ω–∞–ª—ñ–≤
df_input = df_input.copy()
df_input["–ü–æ—Ä—è–¥–æ–∫"] = np.arange(len(df_input))

# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∏
if not validate_structure(df_input):
    st.stop()

available_ba = get_available_ba(df_input)
if not available_ba:
    st.error("‚ùå –£ —Ñ–∞–π–ª—ñ –Ω–µ–º–∞—î –ø–æ–≤–Ω–æ–≥–æ –Ω–∞–±–æ—Ä—É –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –∂–æ–¥–Ω–æ—ó –ë–ê (–ø–æ—Ç—Ä—ñ–±–Ω—ñ –¶—ñ–Ω–∞_*, TRP_*, Affinity_*).")
    st.stop()

st.header("üîß –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó")
st.subheader("üéØ –í–∏–±—ñ—Ä Buying Audience (–ë–ê) –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –°–•")

buying_audiences = {}
col_left, col_right = st.columns([1, 1])
with col_left:
    all_sh = list(df_input["–°–•"].unique())
    for sh in all_sh:
        ba = st.selectbox(f"–°–•: {sh}", available_ba, key=f"ba_{sh}")
        buying_audiences[sh] = ba

if not validate_ba_columns_exist(df_input, buying_audiences):
    st.stop()

st.subheader("üìä –¢–æ–ø-–≥—Ä—É–ø–∏ –∫–∞–Ω–∞–ª—ñ–≤ (–∑–∞—Å—Ç–æ—Å–æ–≤—É—é—Ç—å—Å—è –¥–æ –∫–æ–∂–Ω–æ–≥–æ –°–•)")
st.caption("–ë—é–¥–∂–µ—Ç –∫–æ–∂–Ω–æ—ó —Ç–æ–ø-–≥—Ä—É–ø–∏ —Ñ—ñ–∫—Å—É—î—Ç—å—Å—è —è–∫ –ø–æ—Ç–æ—á–Ω–∞ —Å—É–º–∞ –¶—ñ–Ω–∞*TRP –∫–∞–Ω–∞–ª—ñ–≤ —Ü—ñ—î—ó –≥—Ä—É–ø–∏ –≤ –º–µ–∂–∞—Ö –°–• —ñ —Ä–æ–∑–ø–æ–¥—ñ–ª—è—î—Ç—å—Å—è –≤—Å–µ—Ä–µ–¥–∏–Ω—ñ –≥—Ä—É–ø–∏.")
st.write(
    pd.DataFrame(
        [(g, ", ".join(chs)) for g, chs in TOP_CHANNEL_GROUPS.items()],
        columns=["–ì—Ä—É–ø–∞", "–ö–∞–Ω–∞–ª–∏"]
    )
)

# -----------------------------
#         RUN OPTIMIZATION
# -----------------------------

run = st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç–∏ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—é")

if run:
    # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫
    df_work = df_input.copy()

    # –í–ø–æ—Ä—è–¥–∫—É—î–º–æ –≥—Ä—É–ø—É–≤–∞–Ω–Ω—è –∑–∞ –≤–∏—Ö—ñ–¥–Ω–∏–º –ø–æ—Ä—è–¥–∫–æ–º
    # (groupby(sort=False) + –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è "–ü–æ—Ä—è–¥–æ–∫" –¥–æ–∑–≤–æ–ª—è—î –≤–∏–≤–æ–¥–∏—Ç–∏ —è–∫ –≤ Excel)
    results = run_multi_group_optimization(df_work, buying_audiences)

    # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –≤–∏—Ö—ñ–¥–Ω–∏–π –ø–æ—Ä—è–¥–æ–∫ –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è
    results = results.merge(df_work[["–ö–∞–Ω–∞–ª", "–°–•", "–ü–æ—Ä—è–¥–æ–∫"]], on=["–ö–∞–Ω–∞–ª", "–°–•"], how="left")
    results = results.sort_values(["–°–•", "–ü–æ—Ä—è–¥–æ–∫"], kind="stable").reset_index(drop=True)

    # –î–æ–¥–∞—Ç–∫–æ–≤—ñ —Å–ª—É–∂–±–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏
    results["–ü–æ—á–∞—Ç–∫–æ–≤–∏–π –±—é–¥–∂–µ—Ç"] = results["–¶—ñ–Ω–∞"] * results["TRP"]
    results["is_top"] = results["–ö–∞–Ω–∞–ª"].isin(ALL_TOP_CHANNELS)

    # -----------------------------
    #         TABLES OUTPUT
    # -----------------------------

    st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó –ø–æ –°–• (—É –≤–∏—Ö—ñ–¥–Ω–æ–º—É –ø–æ—Ä—è–¥–∫—É)")
    for sh in results["–°–•"].unique():
        st.markdown(f"#### –°–•: {sh}")
        sh_df = results[results["–°–•"] == sh].copy()

        # –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–µ—Ç–∞–ª—å–Ω–æ—ó —Ç–∞–±–ª–∏—Ü—ñ
        cols_show = [
            "–ö–∞–Ω–∞–ª", "–ü–æ—á–∞—Ç–∫–æ–≤–∏–π –±—é–¥–∂–µ—Ç", "–û–ø—Ç–∏–º–∞–ª—å–Ω–∏–π –±—é–¥–∂–µ—Ç",
            "–¶—ñ–Ω–∞_–¢–†–ü_—Ü—ñ–ª—å–æ–≤–∏–π", "–û–ø—Ç–∏–º–∞–ª—å–Ω–∞ —á–∞—Å—Ç–∫–∞ (%)"
        ]
        st.dataframe(
            sh_df[cols_show],
            use_container_width=True
        )

    # -----------------------------
    #      TOP SUMMARY (per –°–•)
    # -----------------------------

    st.subheader("üìå –°—É–º–∞—Ä–Ω—ñ —á–∞—Å—Ç–∫–∏ –¢–æ–ø-–∫–∞–Ω–∞–ª—ñ–≤ –ø–æ –°–• (–ø—ñ—Å–ª—è –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó)")
    top_share_summary = (
        results[results["is_top"]]
        .groupby("–°–•", sort=False)["–û–ø—Ç–∏–º–∞–ª—å–Ω–∞ —á–∞—Å—Ç–∫–∞ (%)"]
        .sum()
        .reset_index()
        .rename(columns={"–û–ø—Ç–∏–º–∞–ª—å–Ω–∞ —á–∞—Å—Ç–∫–∞ (%)": "–°—É–º–∞—Ä–Ω–∞ —á–∞—Å—Ç–∫–∞ –¢–æ–ø-–∫–∞–Ω–∞–ª—ñ–≤ (%)"})
    )

    # –°–ø–∏—Å–æ–∫ —Ç–æ–ø-–∫–∞–Ω–∞–ª—ñ–≤ —É –ø–æ—Ä—è–¥–∫—É –ø–æ—è–≤–∏ –≤ –∫–æ–∂–Ω–æ–º—É –°–•
    top_channels_per_sh = (
        results[results["is_top"]]
        .sort_values(["–°–•", "–ü–æ—Ä—è–¥–æ–∫"], kind="stable")
        .groupby("–°–•")["–ö–∞–Ω–∞–ª"]
        .apply(lambda s: ", ".join(s.drop_duplicates()))
        .reset_index()
        .rename(columns={"–ö–∞–Ω–∞–ª": "–¢–æ–ø-–∫–∞–Ω–∞–ª–∏"})
    )

    top_summary = pd.merge(top_share_summary, top_channels_per_sh, on="–°–•", how="outer")
    st.dataframe(top_summary, use_container_width=True)

    # -----------------------------
    #           CHARTS
    # -----------------------------

    st.subheader("üìà –ì—Ä–∞—Ñ—ñ–∫–∏ —Å–ø–ª—ñ—Ç—ñ–≤ –ø–æ –∫–æ–∂–Ω–æ–º—É –°–•")

    for sh in results["–°–•"].unique():
        sh_df = results[results["–°–•"] == sh].copy()
        # –¥–ª—è –Ω–∞–æ—á–Ω–æ—Å—Ç—ñ ‚Äî –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω–∏–π –ø–æ—Ä—è–¥–æ–∫ —è–∫ —É —Ñ–∞–π–ª—ñ
        sh_df["–ö–∞–Ω–∞–ª"] = pd.Categorical(sh_df["–ö–∞–Ω–∞–ª"], categories=list(sh_df["–ö–∞–Ω–∞–ª"]), ordered=True)

        fig = px.bar(
            sh_df,
            x="–ö–∞–Ω–∞–ª",
            y="–û–ø—Ç–∏–º–∞–ª—å–Ω–∞ —á–∞—Å—Ç–∫–∞ (%)",
            color=sh_df["is_top"].map({True: "–¢–æ–ø-–∫–∞–Ω–∞–ª", False: "–Ü–Ω—à–∏–π"}),
            hover_data={
                "–û–ø—Ç–∏–º–∞–ª—å–Ω–∞ —á–∞—Å—Ç–∫–∞ (%)": ":.2f",
                "–¶—ñ–Ω–∞_–¢–†–ü_—Ü—ñ–ª—å–æ–≤–∏–π": ":.2f",
                "–ü–æ—á–∞—Ç–∫–æ–≤–∏–π –±—é–¥–∂–µ—Ç": ":.2f",
                "–û–ø—Ç–∏–º–∞–ª—å–Ω–∏–π –±—é–¥–∂–µ—Ç": ":.2f",
                "–ö–∞–Ω–∞–ª": True,
                "is_top": False
            },
            barmode="group",
            title=f"–°–•: {sh} ‚Äî –æ–ø—Ç–∏–º–∞–ª—å–Ω–∞ —á–∞—Å—Ç–∫–∞ –ø–æ –∫–∞–Ω–∞–ª–∞—Ö"
        )
        fig.update_layout(xaxis_title="", yaxis_title="–ß–∞—Å—Ç–∫–∞ (%)")
        st.plotly_chart(fig, use_container_width=True)

    # -----------------------------
    #           EXPORT
    # -----------------------------

    st.subheader("üì• –ï–∫—Å–ø–æ—Ä—Ç —É Excel")
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine="openpyxl") as writer:
        # –î–µ—Ç–∞–ª—å–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
        cols_order = [
            "–°–•", "–ü–æ—Ä—è–¥–æ–∫", "–ö–∞–Ω–∞–ª", "–¶—ñ–Ω–∞", "TRP", "Affinity",
            "–ü–æ—á–∞—Ç–∫–æ–≤–∏–π –±—é–¥–∂–µ—Ç", "–û–ø—Ç–∏–º–∞–ª—å–Ω–∏–π –±—é–¥–∂–µ—Ç", "–û–ø—Ç–∏–º–∞–ª—å–Ω–∞ —á–∞—Å—Ç–∫–∞ (%)", "–¶—ñ–Ω–∞_–¢–†–ü_—Ü—ñ–ª—å–æ–≤–∏–π", "is_top"
        ]
        results[cols_order].to_excel(writer, sheet_name="–û–ø—Ç–∏–º–∞–ª—å–Ω–∏–π —Å–ø–ª—ñ—Ç", index=False)
        top_summary.to_excel(writer, sheet_name="–°—É–º–∞—Ä–Ω—ñ –¢–æ–ø-—á–∞—Å—Ç–∫–∏", index=False)

    st.download_button(
        "‚¨áÔ∏è –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ (Excel)",
        data=output.getvalue(),
        file_name="—Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏_–æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
